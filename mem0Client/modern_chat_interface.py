"""
ç°ä»£åŒ–èŠå¤©ç•Œé¢ - ä½¿ç”¨streamlit-chat-promptç»„ä»¶
"""

import streamlit as st
import base64
import io
import requests
import json
import os
from datetime import datetime
from streamlit_chat_prompt import prompt
import threading
import time
import logging
from typing import Dict, List, Optional
import re

class EnhancedStatusIndicator:
    """å¢å¼ºçš„çŠ¶æ€æŒ‡ç¤ºå™¨ - æä¾›æ›´å¥½çš„ç”¨æˆ·ä½“éªŒ"""

    @staticmethod
    def show_memory_search_progress():
        """æ˜¾ç¤ºè®°å¿†æœç´¢è¿›åº¦"""
        progress_container = st.empty()

        # æ¨¡æ‹Ÿæœç´¢è¿›åº¦
        search_steps = [
            "ğŸ” æ­£åœ¨æœç´¢ç›¸å…³è®°å¿†...",
            "ğŸ“š åˆ†æå†å²å¯¹è¯å†…å®¹...",
            "ğŸ§  åŒ¹é…è¯­ä¹‰ç›¸å…³ä¿¡æ¯...",
            "âœ¨ æ„å»ºæ™ºèƒ½ä¸Šä¸‹æ–‡..."
        ]

        for i, step in enumerate(search_steps):
            progress_container.info(f"{step} ({i+1}/{len(search_steps)})")
            time.sleep(0.3)  # çŸ­æš‚å»¶è¿Ÿæ˜¾ç¤ºè¿›åº¦

        progress_container.empty()

    @staticmethod
    def show_ai_thinking_animation():
        """æ˜¾ç¤ºAIæ€è€ƒåŠ¨ç”»"""
        thinking_container = st.empty()

        thinking_frames = [
            "ğŸ¤– AIæ­£åœ¨æ€è€ƒä¸­.",
            "ğŸ¤– AIæ­£åœ¨æ€è€ƒä¸­..",
            "ğŸ¤– AIæ­£åœ¨æ€è€ƒä¸­...",
            "ğŸ§  åˆ†æé—®é¢˜å†…å®¹.",
            "ğŸ§  åˆ†æé—®é¢˜å†…å®¹..",
            "ğŸ§  åˆ†æé—®é¢˜å†…å®¹...",
            "âš¡ ç”Ÿæˆæ™ºèƒ½å›å¤.",
            "âš¡ ç”Ÿæˆæ™ºèƒ½å›å¤..",
            "âš¡ ç”Ÿæˆæ™ºèƒ½å›å¤..."
        ]

        for frame in thinking_frames:
            thinking_container.info(frame)
            time.sleep(0.2)

        return thinking_container

    @staticmethod
    def show_memory_storage_progress():
        """æ˜¾ç¤ºè®°å¿†å­˜å‚¨è¿›åº¦"""
        storage_steps = [
            "ğŸ” åˆ†æå¯¹è¯é‡è¦æ€§...",
            "ğŸ“ æå–å…³é”®ä¿¡æ¯...",
            "ğŸ§  ç”Ÿæˆè®°å¿†å‘é‡...",
            "ğŸ’¾ å­˜å‚¨åˆ°è®°å¿†åº“...",
            "âœ… è®°å¿†å­˜å‚¨å®Œæˆ"
        ]

        progress_bar = st.progress(0)
        status_text = st.empty()

        for i, step in enumerate(storage_steps):
            progress = (i + 1) / len(storage_steps)
            progress_bar.progress(progress)
            status_text.info(f"{step} ({int(progress * 100)}%)")
            time.sleep(0.5)

        return status_text, progress_bar

class StreamingResponseHandler:
    """æµå¼å“åº”å¤„ç†å™¨ - å¤„ç†AI APIçš„æµå¼å“åº”"""

    @staticmethod
    def parse_sse_line(line: str) -> Dict:
        """è§£æServer-Sent Eventsæ ¼å¼çš„æ•°æ®è¡Œ"""
        if line.startswith('data: '):
            data_content = line[6:]  # ç§»é™¤'data: 'å‰ç¼€
            if data_content.strip() == '[DONE]':
                return {'done': True}
            try:
                import json
                return json.loads(data_content)
            except json.JSONDecodeError:
                return {}
        return {}

    @staticmethod
    def stream_ai_response(url: str, payload: Dict, headers: Dict, timeout: int = 30):
        """å‘é€æµå¼AIè¯·æ±‚å¹¶é€æ­¥è¿”å›å“åº”å†…å®¹"""
        # å¯ç”¨æµå¼å“åº”
        payload['stream'] = True

        try:
            response = requests.post(url, json=payload, headers=headers, timeout=timeout, stream=True)

            if response.status_code != 200:
                yield f"âŒ APIè°ƒç”¨å¤±è´¥: {response.status_code} - {response.text}"
                return

            accumulated_content = ""

            # é€è¡Œè¯»å–æµå¼å“åº”
            for line in response.iter_lines(decode_unicode=True):
                if line:
                    parsed_data = StreamingResponseHandler.parse_sse_line(line)

                    if parsed_data.get('done'):
                        break

                    # æå–å¢é‡å†…å®¹
                    choices = parsed_data.get('choices', [])
                    if choices:
                        delta = choices[0].get('delta', {})
                        content = delta.get('content', '')

                        if content:
                            accumulated_content += content
                            yield accumulated_content

            # å¦‚æœæ²¡æœ‰æ”¶åˆ°ä»»ä½•å†…å®¹ï¼Œè¿”å›é»˜è®¤æ¶ˆæ¯
            if not accumulated_content:
                yield "æŠ±æ­‰ï¼Œæˆ‘æ— æ³•å¤„ç†æ‚¨çš„è¯·æ±‚ã€‚"

        except Exception as e:
            yield f"âŒ å¤„ç†æµå¼å“åº”æ—¶å‡ºé”™: {str(e)}"

class AsyncMemoryProcessor:
    """å¼‚æ­¥è®°å¿†å¤„ç†å™¨ - åœ¨åå°å¤„ç†è®°å¿†å­˜å‚¨ä»»åŠ¡"""

    def __init__(self):
        self.processing_thread = None
        self.is_running = False

    def start_background_processor(self):
        """å¯åŠ¨åå°è®°å¿†å¤„ç†çº¿ç¨‹"""
        if not self.is_running:
            self.is_running = True
            self.processing_thread = threading.Thread(target=self._process_memory_tasks, daemon=True)
            self.processing_thread.start()

    def _process_memory_tasks(self):
        """åå°å¤„ç†è®°å¿†å­˜å‚¨ä»»åŠ¡"""
        while self.is_running:
            try:
                # æ£€æŸ¥æ˜¯å¦æœ‰å¾…å¤„ç†çš„è®°å¿†ä»»åŠ¡
                if 'async_memory_tasks' in st.session_state:
                    pending_tasks = [task for task in st.session_state.async_memory_tasks if task['status'] == 'pending']

                    for task in pending_tasks:
                        try:
                            # æ ‡è®°ä»»åŠ¡ä¸ºå¤„ç†ä¸­
                            task['status'] = 'processing'

                            # è·å–è®°å¿†ç®¡ç†å™¨
                            if 'memory_manager' in st.session_state:
                                memory_manager = st.session_state.memory_manager

                                # æ‰§è¡Œè®°å¿†å­˜å‚¨
                                result = memory_manager.intelligent_store_memory_sync(
                                    task['user_text'],
                                    task['ai_response']
                                )

                                # æ›´æ–°ä»»åŠ¡çŠ¶æ€
                                task['status'] = 'completed'
                                task['result'] = result

                                # æ›´æ–°å¯¹åº”çš„èŠå¤©è®°å½•
                                chat_index = task['chat_index']
                                if (chat_index < len(st.session_state.chat_history) and
                                    st.session_state.chat_history[chat_index]['role'] == 'assistant'):
                                    st.session_state.chat_history[chat_index]['memory_status'] = 'completed'
                                    st.session_state.chat_history[chat_index]['memory_storage'] = result

                            else:
                                task['status'] = 'failed'
                                task['error'] = 'Memory manager not available'

                        except Exception as e:
                            task['status'] = 'failed'
                            task['error'] = str(e)
                            logging.error(f"å¼‚æ­¥è®°å¿†å­˜å‚¨å¤±è´¥: {e}")

                            # æ›´æ–°èŠå¤©è®°å½•çŠ¶æ€
                            chat_index = task['chat_index']
                            if (chat_index < len(st.session_state.chat_history) and
                                st.session_state.chat_history[chat_index]['role'] == 'assistant'):
                                st.session_state.chat_history[chat_index]['memory_status'] = 'failed'

                # æ¸…ç†å®Œæˆçš„ä»»åŠ¡ï¼ˆä¿ç•™æœ€è¿‘10ä¸ªï¼‰
                if 'async_memory_tasks' in st.session_state:
                    completed_tasks = [task for task in st.session_state.async_memory_tasks if task['status'] in ['completed', 'failed']]
                    if len(completed_tasks) > 10:
                        # åªä¿ç•™æœ€è¿‘çš„10ä¸ªå®Œæˆä»»åŠ¡
                        st.session_state.async_memory_tasks = [
                            task for task in st.session_state.async_memory_tasks
                            if task['status'] == 'pending' or task in completed_tasks[-10:]
                        ]

            except Exception as e:
                logging.error(f"å¼‚æ­¥è®°å¿†å¤„ç†å™¨é”™è¯¯: {e}")

            # æ¯ç§’æ£€æŸ¥ä¸€æ¬¡
            time.sleep(1)

    def stop(self):
        """åœæ­¢åå°å¤„ç†å™¨"""
        self.is_running = False

class SimpleImageProcessor:
    """ç®€å•çš„å›¾ç‰‡å¤„ç†å™¨å¤‡ç”¨ç±»"""

    @staticmethod
    def process_image(image_data):
        """ç®€å•çš„å›¾ç‰‡å¤„ç†"""
        try:
            from PIL import Image
            import base64
            import io

            if isinstance(image_data, str):
                # base64å­—ç¬¦ä¸²
                if image_data.startswith('data:image'):
                    image_data = image_data.split(',')[1]

                img_bytes = base64.b64decode(image_data)
                img = Image.open(io.BytesIO(img_bytes))
            else:
                # æ–‡ä»¶å¯¹è±¡
                img = Image.open(image_data)

            # è·å–åŸºæœ¬ä¿¡æ¯
            width, height = img.size
            format_type = img.format or 'PNG'

            # è½¬æ¢ä¸ºbase64
            buffer = io.BytesIO()
            img.save(buffer, format=format_type)
            size_bytes = len(buffer.getvalue())
            buffer.seek(0)
            img_base64 = base64.b64encode(buffer.getvalue()).decode()

            return {
                "success": True,
                "base64": img_base64,
                "width": width,
                "height": height,
                "format": format_type,
                "size_bytes": size_bytes,
                "size_mb": round(size_bytes / 1024 / 1024, 2)
            }
        except Exception as e:
            return {
                "success": False,
                "error": str(e)
            }

def ensure_multimodal_processor():
    """ç¡®ä¿multimodal_processorå·²åˆå§‹åŒ–"""
    if 'multimodal_processor' not in st.session_state:
        try:
            from multimodal_model_selector import MultimodalProcessor
            st.session_state.multimodal_processor = MultimodalProcessor()
        except Exception as e:
            st.error(f"âŒ åˆå§‹åŒ–å¤šæ¨¡æ€å¤„ç†å™¨å¤±è´¥: {str(e)}")
            # åˆ›å»ºä¸€ä¸ªç®€å•çš„å¤‡ç”¨å¤„ç†å™¨
            st.session_state.multimodal_processor = SimpleImageProcessor()

def handle_modern_chat_message(user_text: str, image_info: dict = None):
    """å¤„ç†ç°ä»£åŒ–èŠå¤©æ¶ˆæ¯ - é›†æˆæ™ºèƒ½è®°å¿†åŠŸèƒ½"""
    try:
        # åˆå§‹åŒ–æ™ºèƒ½è®°å¿†ç®¡ç†å™¨
        if 'memory_manager' not in st.session_state:
            from intelligent_memory_manager import IntelligentMemoryManager
            from api_patches import MemoryAPIPatched

            user_id = getattr(st.session_state, 'user_settings', {}).get('user_id', 'default_user')
            mem0_api_url = MemoryAPIPatched.get_api_url()

            st.session_state.memory_manager = IntelligentMemoryManager(
                mem0_api_url=mem0_api_url,
                user_id=user_id
            )

        memory_manager = st.session_state.memory_manager

        # æ™ºèƒ½æ¨¡å‹é€‰æ‹©
        has_image = image_info is not None and image_info.get("success", False)
        content_for_analysis = user_text or "å›¾ç‰‡åˆ†æè¯·æ±‚"

        # ç¡®ä¿model_selectorå·²åˆå§‹åŒ–
        if 'model_selector' not in st.session_state:
            from dynamic_model_selector import DynamicModelSelector
            api_key = st.session_state.get('api_settings', {}).get('api_key', 'q1q2q3q4')
            st.session_state.model_selector = DynamicModelSelector(
                api_base_url='http://gemini-balance:8000',
                api_key=api_key
            )

        # é€‰æ‹©åˆé€‚çš„æ¨¡å‹
        model_info = st.session_state.model_selector.select_optimal_model(
            user_query=content_for_analysis,
            has_image=has_image
        )

        # ğŸ§  ç®€åŒ–è®°å¿†æ£€ç´¢ï¼šé»˜è®¤æ€»æ˜¯æ£€ç´¢è®°å¿†ï¼ˆé™¤éæ˜¯æ˜æ˜¾çš„åƒåœ¾å†…å®¹ï¼‰
        should_skip_memory = (
            len(user_text.strip()) < 2 or  # å¤ªçŸ­
            user_text.strip() in ['hi', 'hello', 'ä½ å¥½', 'ok', 'yes', 'no'] or  # ç®€å•é—®å€™
            user_text.strip().startswith('/')  # å‘½ä»¤
        )

        if not should_skip_memory:
            # ğŸ¯ ä½¿ç”¨å¢å¼ºçš„çŠ¶æ€æŒ‡ç¤ºå™¨
            search_progress = st.empty()
            search_progress.info("ğŸ” æ­£åœ¨æœç´¢ç›¸å…³è®°å¿†...")

            # ğŸ” æœç´¢ç›¸å…³è®°å¿†ï¼ˆä½¿ç”¨åŒæ­¥ç‰ˆæœ¬ï¼‰
            relevant_memories = memory_manager.search_relevant_memories_sync(user_text, limit=5)

            search_progress.success(f"âœ… æ‰¾åˆ° {len(relevant_memories)} æ¡ç›¸å…³è®°å¿†")
            time.sleep(0.5)  # çŸ­æš‚æ˜¾ç¤ºç»“æœ
            search_progress.empty()

            # ğŸ“ æ„å»ºå¢å¼ºçš„ä¸Šä¸‹æ–‡
            enhanced_user_input = memory_manager.build_context_with_memories(
                user_text, relevant_memories, {'needs_memory': True, 'confidence': 1.0}
            )
        else:
            enhanced_user_input = user_text
            relevant_memories = []

        # ç®€åŒ–çš„è®°å¿†åˆ†æç»“æœ
        memory_analysis = {
            'needs_memory': not should_skip_memory,
            'confidence': 1.0 if not should_skip_memory else 0.0,
            'trigger_type': 'default' if not should_skip_memory else 'skip',
            'keywords': []
        }

        # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ°èŠå¤©å†å²
        user_message = {
            "role": "user",
            "content": user_text,
            "timestamp": st.session_state.get('current_time', ''),
            "model_info": model_info,
            "memory_analysis": memory_analysis,
            "used_memories": len(relevant_memories)
        }

        if image_info:
            user_message["image_info"] = image_info

        st.session_state.chat_history.append(user_message)
        
        # ğŸ¤– æ™ºèƒ½å¯¹è¯ç³»ç»Ÿ - é›†æˆè®°å¿†åŠŸèƒ½

        # è·å–ç”¨æˆ·ID
        user_id = getattr(st.session_state, 'user_settings', {}).get('user_id', 'default_user')

        # è°ƒç”¨gemini-balanceè·å–AIå›å¤
        gemini_balance_url = os.getenv('GEMINI_BALANCE_URL', 'http://gemini-balance:8000/v1')
        auth_token = st.session_state.get('api_settings', {}).get('api_key') or os.getenv('INTEGRATED_GEMINI_BALANCE_TOKEN', os.getenv('GEMINI_BALANCE_TOKEN', 'q1q2q3q4'))

        # æ„å»ºæ™ºèƒ½å¯¹è¯æ¶ˆæ¯
        messages = [
            {
                "role": "system",
                "content": """ä½ æ˜¯ä¸€ä¸ªå…·æœ‰è®°å¿†èƒ½åŠ›çš„æ™ºèƒ½åŠ©æ‰‹ã€‚ä½ èƒ½å¤Ÿï¼š
1. è®°ä½ç”¨æˆ·çš„ä¸ªäººä¿¡æ¯ã€åå¥½å’Œå†å²å¯¹è¯
2. åŸºäºå†å²è®°å¿†æä¾›ä¸ªæ€§åŒ–çš„å›å¤
3. è‡ªç„¶åœ°å¼•ç”¨ç›¸å…³çš„å†å²ä¿¡æ¯
4. åœ¨ä¿¡æ¯ä¸ç¡®å®šæ—¶ä¸»åŠ¨è¯¢é—®ç”¨æˆ·ç¡®è®¤

è¯·ç”¨ä¸­æ–‡å›å¤ï¼Œä¿æŒå¯¹è¯çš„è‡ªç„¶æ€§å’Œè¿è´¯æ€§ã€‚"""
            }
        ]

        # æ·»åŠ èŠå¤©å†å²ï¼ˆæœ€è¿‘5æ¡ï¼Œä¸åŒ…æ‹¬å½“å‰æ¶ˆæ¯ï¼‰
        recent_history = st.session_state.chat_history[-10:] if len(st.session_state.chat_history) > 1 else []
        for msg in recent_history:
            if msg['role'] in ['user', 'assistant']:
                messages.append({
                    "role": msg['role'],
                    "content": msg['content']
                })

        # æ·»åŠ å¢å¼ºçš„ç”¨æˆ·æ¶ˆæ¯ï¼ˆåŒ…å«è®°å¿†ä¸Šä¸‹æ–‡å’Œå›¾ç‰‡ï¼‰
        user_message_content = enhanced_user_input  # ä½¿ç”¨å¢å¼ºçš„è¾“å…¥è€Œä¸æ˜¯åŸå§‹è¾“å…¥

        # å¦‚æœæœ‰å›¾ç‰‡ï¼Œæ„å»ºå¤šæ¨¡æ€æ¶ˆæ¯æ ¼å¼
        if image_info and image_info.get("success"):
            # ä½¿ç”¨OpenAIå…¼å®¹çš„å¤šæ¨¡æ€æ¶ˆæ¯æ ¼å¼
            messages.append({
                "role": "user",
                "content": [
                    {
                        "type": "text",
                        "text": user_message_content
                    },
                    {
                        "type": "image_url",
                        "image_url": {
                            "url": f"data:image/{image_info.get('format', 'png').lower()};base64,{image_info['base64']}"
                        }
                    }
                ]
            })
        else:
            # çº¯æ–‡æœ¬æ¶ˆæ¯
            messages.append({
                "role": "user",
                "content": user_message_content
            })

        # è°ƒç”¨gemini-balance API
        payload = {
            "model": model_info.get('selected_model', 'gemini-1.5-flash'),
            "messages": messages,
            "temperature": 0.7,
            "max_tokens": 2000
        }

        headers = {
            "Authorization": f"Bearer {auth_token}",
            "Content-Type": "application/json"
        }

        # ğŸš€ æµå¼AIå“åº”å®ç° - ä½¿ç”¨çœŸæ­£çš„æµå¼API
        ai_response = ""

        # ğŸ¯ æ˜¾ç¤ºå¢å¼ºçš„AIæ€è€ƒçŠ¶æ€
        thinking_status = st.empty()
        thinking_status.info("ğŸ§  AIæ­£åœ¨åˆ†ææ‚¨çš„é—®é¢˜...")

        # å…ˆæ·»åŠ ä¸€ä¸ªå ä½ç¬¦åˆ°èŠå¤©å†å²
        placeholder_index = len(st.session_state.chat_history)
        st.session_state.chat_history.append({
            "role": "assistant",
            "content": "âš¡ æ­£åœ¨ç”Ÿæˆå›å¤...",
            "timestamp": st.session_state.get('current_time', ''),
            "model": model_info.get('selected_model', 'unknown'),
            "memory_status": "pending",
            "streaming": True,
            "generation_stage": "thinking"
        })

        # ä½¿ç”¨æµå¼APIè·å–å›å¤
        try:
            # å¯ç”¨æµå¼å“åº”
            payload['stream'] = True

            response = requests.post(
                f"{gemini_balance_url}/chat/completions",
                json=payload,
                headers=headers,
                timeout=30,
                stream=True
            )

            if response.status_code != 200:
                raise Exception(f"Gemini Balance APIè°ƒç”¨å¤±è´¥: {response.status_code} - {response.text}")

            accumulated_content = ""
            first_content_received = False

            # æ›´æ–°çŠ¶æ€ï¼šå¼€å§‹æ¥æ”¶æµå¼å“åº”
            thinking_status.info("ğŸ“¡ æ­£åœ¨æ¥æ”¶AIå›å¤...")

            # å¤„ç†æµå¼å“åº”
            for line in response.iter_lines(decode_unicode=True):
                if line and line.startswith('data: '):
                    data_content = line[6:]  # ç§»é™¤'data: 'å‰ç¼€

                    if data_content.strip() == '[DONE]':
                        break

                    try:
                        import json
                        parsed_data = json.loads(data_content)
                        choices = parsed_data.get('choices', [])

                        if choices:
                            delta = choices[0].get('delta', {})
                            content = delta.get('content', '')

                            if content:
                                accumulated_content += content

                                # ç¬¬ä¸€æ¬¡æ”¶åˆ°å†…å®¹æ—¶æ›´æ–°çŠ¶æ€
                                if not first_content_received:
                                    thinking_status.success("âœ¨ å¼€å§‹ç”Ÿæˆå›å¤...")
                                    first_content_received = True

                                # æ›´æ–°èŠå¤©å†å²ä¸­çš„æ¶ˆæ¯
                                st.session_state.chat_history[placeholder_index]["content"] = accumulated_content
                                st.session_state.chat_history[placeholder_index]["streaming"] = True
                                st.session_state.chat_history[placeholder_index]["generation_stage"] = "streaming"

                    except json.JSONDecodeError:
                        continue

            ai_response = accumulated_content if accumulated_content else "æŠ±æ­‰ï¼Œæˆ‘æ— æ³•å¤„ç†æ‚¨çš„è¯·æ±‚ã€‚"

            # å®Œæˆæµå¼å“åº”ï¼Œæ›´æ–°æœ€ç»ˆçŠ¶æ€
            thinking_status.success("ğŸ‰ AIå›å¤ç”Ÿæˆå®Œæˆï¼")
            time.sleep(0.5)
            thinking_status.empty()

            st.session_state.chat_history[placeholder_index]["content"] = ai_response
            st.session_state.chat_history[placeholder_index]["streaming"] = False
            st.session_state.chat_history[placeholder_index]["memory_status"] = "processing"
            st.session_state.chat_history[placeholder_index]["generation_stage"] = "completed"

        except Exception as e:
            ai_response = f"âŒ è·å–AIå›å¤æ—¶å‡ºé”™: {str(e)}"
            # æ›´æ–°é”™è¯¯çŠ¶æ€
            thinking_status.error(f"âŒ AIå›å¤ç”Ÿæˆå¤±è´¥: {str(e)}")
            time.sleep(1)
            thinking_status.empty()

            # æ›´æ–°é”™è¯¯æ¶ˆæ¯
            st.session_state.chat_history[placeholder_index]["content"] = ai_response
            st.session_state.chat_history[placeholder_index]["streaming"] = False
            st.session_state.chat_history[placeholder_index]["memory_status"] = "failed"
            st.session_state.chat_history[placeholder_index]["generation_stage"] = "failed"

        # ğŸ§  æ™ºèƒ½è®°å¿†å­˜å‚¨ï¼šå¼‚æ­¥å¤„ç†ï¼Œä¸é˜»å¡ç”¨æˆ·ç•Œé¢
        memory_storage_result = None

        # AIå›å¤å·²é€šè¿‡æµå¼å“åº”æ·»åŠ åˆ°èŠå¤©å†å²ï¼Œç°åœ¨å¯åŠ¨å¼‚æ­¥è®°å¿†å­˜å‚¨

        # å¼‚æ­¥å¯åŠ¨è®°å¿†å­˜å‚¨ä»»åŠ¡
        try:
            # ä½¿ç”¨session stateæ¥è·Ÿè¸ªå¼‚æ­¥ä»»åŠ¡
            if 'async_memory_tasks' not in st.session_state:
                st.session_state.async_memory_tasks = []

            # åˆ›å»ºå¼‚æ­¥ä»»åŠ¡ä¿¡æ¯
            task_info = {
                'user_text': user_text,
                'ai_response': ai_response,
                'chat_index': len(st.session_state.chat_history) - 1,  # è®°å½•å¯¹åº”çš„èŠå¤©è®°å½•ç´¢å¼•
                'status': 'pending',
                'timestamp': datetime.now()
            }
            st.session_state.async_memory_tasks.append(task_info)

            # æ˜¾ç¤ºå¢å¼ºçš„åå°å¤„ç†æç¤º
            memory_status = st.empty()
            memory_status.info("ğŸ§  å¯åŠ¨æ™ºèƒ½è®°å¿†å­˜å‚¨...")
            time.sleep(0.3)
            memory_status.success("âœ… è®°å¿†å­˜å‚¨ä»»åŠ¡å·²åŠ å…¥é˜Ÿåˆ—ï¼Œæ­£åœ¨åå°å¤„ç†")
            time.sleep(1)
            memory_status.empty()

        except Exception as memory_error:
            # è®°å¿†å­˜å‚¨å¤±è´¥ä¸å½±å“å¯¹è¯åŠŸèƒ½
            print(f"å¯åŠ¨å¼‚æ­¥è®°å¿†å­˜å‚¨å¤±è´¥: {memory_error}")
            # æ›´æ–°èŠå¤©è®°å½•ä¸­çš„è®°å¿†çŠ¶æ€
            if st.session_state.chat_history:
                st.session_state.chat_history[-1]["memory_status"] = "failed"

        # AIå›å¤å·²åœ¨ä¸Šé¢çš„å¼‚æ­¥å¤„ç†ä¸­æ·»åŠ åˆ°èŠå¤©å†å²
        # æ›´æ–°æœ€åä¸€æ¡æ¶ˆæ¯çš„è®°å¿†ä¿¡æ¯
        if st.session_state.chat_history:
            last_message = st.session_state.chat_history[-1]
            last_message["used_memories"] = len(relevant_memories) if relevant_memories else 0

        # æ›´æ–°å­¦ä¹ çŠ¶æ€
        st.session_state.learning_state = "active"

        # å¯¹è¯æˆåŠŸåè‡ªåŠ¨æ›´æ–°è¿æ¥çŠ¶æ€
        st.session_state.api_connected = True
        if 'api_settings' in st.session_state:
            st.session_state.api_settings['connected'] = True

        # æ˜¾ç¤ºè®°å¿†é€æ˜åº¦ä¿¡æ¯ï¼ˆå¯é€‰ï¼‰
        if relevant_memories:
            with st.expander(f"ğŸ§  æœ¬æ¬¡å¯¹è¯ä½¿ç”¨äº† {len(relevant_memories)} æ¡å†å²è®°å¿†", expanded=False):
                for i, memory in enumerate(relevant_memories[:3], 1):
                    st.write(f"**è®°å¿† {i}** (ç›¸å…³åº¦: {memory.get('score', 0.0):.2f})")
                    st.write(memory.get('memory', '')[:200] + "..." if len(memory.get('memory', '')) > 200 else memory.get('memory', ''))
                    st.write("---")

        st.rerun()

    except requests.exceptions.Timeout:
        # å¯¹è¯å¤±è´¥æ—¶æ›´æ–°è¿æ¥çŠ¶æ€
        st.session_state.api_connected = False
        if 'api_settings' in st.session_state:
            st.session_state.api_settings['connected'] = False
        st.error("â° è¯·æ±‚è¶…æ—¶ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–ç¨åé‡è¯•")
        st.info("ğŸ’¡ å»ºè®®ï¼šæ£€æŸ¥AIæœåŠ¡æ˜¯å¦æ­£å¸¸è¿è¡Œ")
    except requests.exceptions.ConnectionError:
        # å¯¹è¯å¤±è´¥æ—¶æ›´æ–°è¿æ¥çŠ¶æ€
        st.session_state.api_connected = False
        if 'api_settings' in st.session_state:
            st.session_state.api_settings['connected'] = False
        st.error("ğŸ”Œ æ— æ³•è¿æ¥åˆ°AIæœåŠ¡ï¼Œè¯·æ£€æŸ¥æœåŠ¡çŠ¶æ€")
        st.info("ğŸ’¡ å»ºè®®ï¼šç¡®è®¤gemini-balanceæœåŠ¡æ­£åœ¨è¿è¡Œ")
    except Exception as e:
        # å¯¹è¯å¤±è´¥æ—¶æ›´æ–°è¿æ¥çŠ¶æ€
        st.session_state.api_connected = False
        if 'api_settings' in st.session_state:
            st.session_state.api_settings['connected'] = False
        st.error(f"âŒ å¤„ç†æ¶ˆæ¯æ—¶å‡ºé”™: {str(e)}")
        st.info("ğŸ’¡ å»ºè®®ï¼š\n1. æ£€æŸ¥ç½‘ç»œè¿æ¥\n2. ç¡®è®¤AIæœåŠ¡æ­£å¸¸è¿è¡Œ\n3. å¦‚é—®é¢˜æŒç»­ï¼Œè¯·è”ç³»ç®¡ç†å‘˜")

def modern_smart_chat_interface():
    """ç°ä»£åŒ–æ™ºèƒ½å¯¹è¯ç•Œé¢"""
    st.header("ğŸ§  æ™ºèƒ½å¯¹è¯ - AIè®°å¿†å­¦ä¹ ä¸­å¿ƒ")
    st.markdown("ä¸AIåŠ©æ‰‹å¯¹è¯ï¼Œè§‚å¯ŸAIå¦‚ä½•è‡ªåŠ¨å­¦ä¹ å’Œè®°å¿†æ‚¨çš„åå¥½")

    # æ·»åŠ è‡ªå®šä¹‰CSSæ ·å¼
    st.markdown("""
    <style>
    .status-indicator {
        padding: 8px 12px;
        border-radius: 6px;
        margin: 4px 0;
        font-size: 0.9em;
        animation: pulse 2s infinite;
    }

    .status-thinking {
        background: linear-gradient(45deg, #e3f2fd, #bbdefb);
        border-left: 4px solid #2196f3;
    }

    .status-streaming {
        background: linear-gradient(45deg, #f3e5f5, #e1bee7);
        border-left: 4px solid #9c27b0;
    }

    .status-memory {
        background: linear-gradient(45deg, #e8f5e8, #c8e6c9);
        border-left: 4px solid #4caf50;
    }

    @keyframes pulse {
        0% { opacity: 1; }
        50% { opacity: 0.7; }
        100% { opacity: 1; }
    }

    .progress-container {
        background: #f5f5f5;
        border-radius: 10px;
        padding: 10px;
        margin: 8px 0;
    }
    </style>
    """, unsafe_allow_html=True)

    # åˆå§‹åŒ–å¼‚æ­¥è®°å¿†å¤„ç†å™¨
    if 'async_memory_processor' not in st.session_state:
        st.session_state.async_memory_processor = AsyncMemoryProcessor()
        st.session_state.async_memory_processor.start_background_processor()

    # åˆå§‹åŒ–å¼‚æ­¥ä»»åŠ¡åˆ—è¡¨
    if 'async_memory_tasks' not in st.session_state:
        st.session_state.async_memory_tasks = []

    # åˆ›å»ºå·¦å³åˆ†åˆ—å¸ƒå±€
    chat_col, memory_col = st.columns([2, 1])

    with chat_col:
        st.subheader("ğŸ’¬ å¯¹è¯åŒºåŸŸ")

        # æ˜¾ç¤ºèŠå¤©å†å² - ä½¿ç”¨ç°ä»£åŒ–çš„èŠå¤©æ¶ˆæ¯ç»„ä»¶
        for message in st.session_state.chat_history:
            with st.chat_message(message['role']):
                if message['role'] == 'user':
                    st.write(message['content'])
                    # æ˜¾ç¤ºå›¾ç‰‡ï¼ˆå¦‚æœæœ‰ï¼‰
                    if 'image_info' in message and message['image_info']:
                        st.caption("ğŸ“· åŒ…å«å›¾ç‰‡")
                    # æ˜¾ç¤ºæ¨¡å‹ä¿¡æ¯ï¼ˆå¦‚æœæœ‰ï¼‰
                    if 'model_info' in message:
                        model_info = message['model_info']
                        st.caption(f"ğŸ¤– ä½¿ç”¨æ¨¡å‹: {model_info.get('selected_model', 'unknown')}")
                else:
                    # æ˜¾ç¤ºAIå›å¤å†…å®¹
                    st.write(message['content'])

                    # æ˜¾ç¤ºæ¨¡å‹ä¿¡æ¯
                    if 'model' in message:
                        st.caption(f"ğŸ¤– æ¨¡å‹: {message['model']}")

                    # æ˜¾ç¤ºç”Ÿæˆé˜¶æ®µçŠ¶æ€
                    if 'generation_stage' in message:
                        stage = message['generation_stage']
                        if stage == 'thinking':
                            st.caption("ğŸ§  AIæ­£åœ¨æ€è€ƒ...")
                        elif stage == 'streaming':
                            st.caption("âš¡ æ­£åœ¨ç”Ÿæˆå›å¤...")
                        elif stage == 'completed':
                            st.caption("âœ¨ å›å¤ç”Ÿæˆå®Œæˆ")
                        elif stage == 'failed':
                            st.caption("âŒ ç”Ÿæˆå¤±è´¥")

                    # æ˜¾ç¤ºæµå¼å“åº”çŠ¶æ€ï¼ˆå‘åå…¼å®¹ï¼‰
                    elif message.get('streaming', False):
                        st.caption("âš¡ æ­£åœ¨ç”Ÿæˆå›å¤...")

                    # æ˜¾ç¤ºè®°å¿†å¤„ç†çŠ¶æ€
                    if 'memory_status' in message:
                        status = message['memory_status']
                        if status == 'pending':
                            st.caption("â³ å‡†å¤‡å­˜å‚¨è®°å¿†...")
                        elif status == 'processing':
                            st.caption("ğŸ’­ è®°å¿†å­˜å‚¨ä¸­...")
                        elif status == 'completed':
                            if 'memory_storage' in message and message['memory_storage']:
                                result = message['memory_storage']
                                if result.get('stored'):
                                    st.caption(f"âœ… {result.get('reason', 'è®°å¿†å·²å­˜å‚¨')}")
                                else:
                                    st.caption(f"â„¹ï¸ {result.get('reason', 'æœªå­˜å‚¨è®°å¿†')}")
                        elif status == 'failed':
                            st.caption("âš ï¸ è®°å¿†å­˜å‚¨å¤±è´¥")

                    # æ˜¾ç¤ºä½¿ç”¨çš„è®°å¿†æ•°é‡
                    if 'used_memories' in message and message['used_memories'] > 0:
                        st.caption(f"ğŸ§  ä½¿ç”¨äº† {message['used_memories']} æ¡ç›¸å…³è®°å¿†")

                    # æ˜¾ç¤ºå“åº”æ—¶é—´æ ‡è®°ï¼ˆå¦‚æœæœ‰ï¼‰
                    if 'response_time' in message:
                        st.caption(f"âš¡ {message['response_time']}")

        # ç°ä»£åŒ–èŠå¤©è¾“å…¥ç»„ä»¶ - æ”¯æŒEnterå‘é€ï¼ŒShift+Enteræ¢è¡Œï¼Œå‰ªè´´æ¿ç²˜è´´
        prompt_result = prompt(
            name="chat_input",
            key="modern_chat_prompt",
            placeholder="è¾“å…¥æ‚¨çš„æ¶ˆæ¯... (Enterå‘é€ï¼ŒShift+Enteræ¢è¡Œï¼Œæ”¯æŒç²˜è´´å›¾ç‰‡)",
            main_bottom=False,  # ä¸å›ºå®šåœ¨é¡µé¢åº•éƒ¨ï¼Œè€Œæ˜¯åœ¨å¯¹è¯åŒºåŸŸå†…
        )

        # å¤„ç†ç°ä»£åŒ–èŠå¤©è¾“å…¥
        if prompt_result:
            # è·å–ç”¨æˆ·è¾“å…¥çš„æ–‡æœ¬
            user_text = prompt_result.text if prompt_result.text else ""
            user_text = user_text.strip()
            
            # è·å–ç”¨æˆ·ä¸Šä¼ /ç²˜è´´çš„å›¾ç‰‡
            user_images = prompt_result.images if prompt_result.images else []
            
            if user_text or user_images:
                # å¤„ç†å›¾ç‰‡æ•°æ®
                image_info = None
                if user_images:
                    try:
                        # ç¡®ä¿å¤šæ¨¡æ€å¤„ç†å™¨å·²åˆå§‹åŒ–
                        ensure_multimodal_processor()

                        # ä½¿ç”¨ç¬¬ä¸€å¼ å›¾ç‰‡
                        first_image = user_images[0]

                        # first_image æ˜¯ FileData å¯¹è±¡ï¼Œç›´æ¥ä½¿ç”¨å…¶ data å±æ€§ï¼ˆbase64æ•°æ®ï¼‰
                        img_base64 = first_image.data

                        # å¤„ç†å›¾ç‰‡
                        image_info = st.session_state.multimodal_processor.process_image(img_base64)
                        if not image_info["success"]:
                            st.error(f"âŒ å›¾ç‰‡å¤„ç†å¤±è´¥: {image_info['error']}")
                            image_info = None
                    except Exception as e:
                        st.error(f"âŒ å›¾ç‰‡å¤„ç†å¼‚å¸¸: {str(e)}")
                        image_info = None
                
                # å‘é€æ¶ˆæ¯
                if user_text:
                    handle_modern_chat_message(user_text, image_info)

        # æ¸…ç©ºå¯¹è¯æŒ‰é’®
        if st.button("ğŸ§¹ æ¸…ç©ºå¯¹è¯", type="secondary"):
            st.session_state.chat_history = []
            st.rerun()

    with memory_col:
        st.subheader("ğŸ§  AIè®°å¿†å­¦ä¹ ")
        display_real_time_memory_learning()

        # è‡ªåŠ¨åˆ·æ–°æœºåˆ¶ - å¦‚æœæœ‰æ´»è·ƒçš„è®°å¿†ä»»åŠ¡ï¼Œæ¯3ç§’åˆ·æ–°ä¸€æ¬¡
        if 'async_memory_tasks' in st.session_state:
            active_tasks = [task for task in st.session_state.async_memory_tasks
                          if task['status'] in ['pending', 'processing']]
            if active_tasks:
                # ä½¿ç”¨JavaScriptè‡ªåŠ¨åˆ·æ–°
                st.markdown("""
                <script>
                setTimeout(function() {
                    window.parent.document.querySelector('[data-testid="stAppViewContainer"]').dispatchEvent(
                        new KeyboardEvent('keydown', {key: 'r', ctrlKey: true})
                    );
                }, 3000);
                </script>
                """, unsafe_allow_html=True)

def display_real_time_memory_learning():
    """æ˜¾ç¤ºAIå®æ—¶è®°å¿†å­¦ä¹ è¿‡ç¨‹"""

    # æ˜¾ç¤ºå¼‚æ­¥è®°å¿†å¤„ç†çŠ¶æ€
    if 'async_memory_tasks' in st.session_state:
        pending_tasks = [task for task in st.session_state.async_memory_tasks if task['status'] == 'pending']
        processing_tasks = [task for task in st.session_state.async_memory_tasks if task['status'] == 'processing']

        if pending_tasks or processing_tasks:
            st.markdown("### âš¡ è®°å¿†å¤„ç†çŠ¶æ€")
            total_active = len(pending_tasks) + len(processing_tasks)

            if processing_tasks:
                st.info(f"ğŸ§  æ­£åœ¨å¤„ç† {len(processing_tasks)} ä¸ªè®°å¿†ä»»åŠ¡...")
                # æ˜¾ç¤ºå¤„ç†è¿›åº¦
                for i, task in enumerate(processing_tasks[:3]):  # æœ€å¤šæ˜¾ç¤º3ä¸ª
                    elapsed = (datetime.now() - task['timestamp']).total_seconds()
                    st.caption(f"ä»»åŠ¡ {i+1}: å·²å¤„ç† {elapsed:.1f}ç§’")

            if pending_tasks:
                st.caption(f"ğŸ“ é˜Ÿåˆ—ä¸­è¿˜æœ‰ {len(pending_tasks)} ä¸ªä»»åŠ¡ç­‰å¾…å¤„ç†")

    # è·å–æœ€è¿‘å­¦ä¹ çš„è®°å¿†
    if 'recent_memories' not in st.session_state:
        st.session_state.recent_memories = []

    # æ˜¾ç¤ºæœ€è¿‘å­¦ä¹ çš„è®°å¿†
    if st.session_state.recent_memories:
        st.markdown("### ğŸ†• AIåˆšå­¦åˆ°çš„è®°å¿†")
        for memory in st.session_state.recent_memories[-3:]:  # æ˜¾ç¤ºæœ€è¿‘3æ¡
            with st.expander(f"ğŸ’¡ {memory.get('summary', 'æ–°è®°å¿†')}", expanded=True):
                st.write(f"**å†…å®¹**: {memory.get('content', '')}")
                st.write(f"**æ—¶é—´**: {memory.get('timestamp', '')}")
                if memory.get('confidence'):
                    st.progress(memory['confidence'], text=f"ç½®ä¿¡åº¦: {memory['confidence']:.0%}")
    else:
        st.info("ğŸ’­ AIæ­£åœ¨ç­‰å¾…å­¦ä¹ æ–°çš„è®°å¿†...")

    # æ˜¾ç¤ºè®°å¿†ç»Ÿè®¡
    st.markdown("### ğŸ“Š è®°å¿†ç»Ÿè®¡")

    # åˆå§‹åŒ–å˜é‡
    all_memories = []
    user_id = getattr(st.session_state, 'user_settings', {}).get('user_id', 'default_user')
    import os
    api_base_url = getattr(st.session_state, 'api_base_url', os.getenv('MEM0_API_URL', 'http://localhost:8888'))

    try:

        # è·å–è®°å¿†åˆ—è¡¨æ¥è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        import requests
        from datetime import datetime, date

        memories_response = requests.get(
            f"{api_base_url}/memories",
            params={"user_id": user_id},
            timeout=10
        )

        if memories_response.status_code == 200:
            memories_data = memories_response.json()

            # å¤„ç†APIè¿”å›çš„æ•°æ®ç»“æ„
            if isinstance(memories_data, dict) and 'results' in memories_data:
                if isinstance(memories_data['results'], dict) and 'results' in memories_data['results']:
                    all_memories = memories_data['results']['results']
                else:
                    all_memories = memories_data['results']
            elif isinstance(memories_data, list):
                all_memories = memories_data
            else:
                all_memories = []

            # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
            total_memories = len(all_memories)
            today = date.today().isoformat()
            today_added = sum(1 for memory in all_memories
                            if memory.get('created_at', '').startswith(today))

            col1, col2 = st.columns(2)
            with col1:
                st.metric("æ€»è®°å¿†æ•°é‡", total_memories)
            with col2:
                st.metric("ä»Šæ—¥æ–°å¢", today_added)

        else:
            st.error("âŒ æ— æ³•è·å–è®°å¿†ç»Ÿè®¡")
            
    except Exception as e:
        st.error(f"âŒ è·å–ç»Ÿè®¡å¤±è´¥: {str(e)}")

    # æ˜¾ç¤ºè®°å¿†æ ‡ç­¾äº‘
    st.markdown("### ğŸ·ï¸ è®°å¿†æ ‡ç­¾")
    
    try:
        # ä»å·²è·å–çš„è®°å¿†ä¸­æå–æ ‡ç­¾
        if 'all_memories' in locals() and all_memories:
            # æå–è®°å¿†ä¸­çš„å…³é”®è¯ä½œä¸ºæ ‡ç­¾
            tags = set()
            for memory in all_memories[:10]:  # åªå¤„ç†æœ€è¿‘10æ¡
                content = memory.get('memory', memory.get('content', ''))
                # ç®€å•çš„å…³é”®è¯æå–
                words = content.split()
                for word in words:
                    if len(word) > 2 and word.isalpha():
                        tags.add(word)

            if tags:
                tag_list = list(tags)[:8]  # æœ€å¤šæ˜¾ç¤º8ä¸ªæ ‡ç­¾
                cols = st.columns(2)
                for i, tag in enumerate(tag_list):
                    with cols[i % 2]:
                        st.button(f"#{tag}", disabled=True, key=f"tag_{i}")
            else:
                st.info("ğŸ·ï¸ æš‚æ— æ ‡ç­¾")
        else:
            st.info("ğŸ·ï¸ æš‚æ— æ ‡ç­¾")

    except Exception as e:
        st.info("ğŸ·ï¸ æ ‡ç­¾åŠ è½½ä¸­...")

    # å­¦ä¹ çŠ¶æ€æŒ‡ç¤ºå™¨
    st.markdown("### âš¡ å­¦ä¹ çŠ¶æ€")
    
    if len(st.session_state.chat_history) > 0:
        st.success("ğŸŸ¢ AIæ­£åœ¨ç§¯æå­¦ä¹ ä¸­")
        st.write("AIä¼šè‡ªåŠ¨ä»æ¯æ¬¡å¯¹è¯ä¸­æå–é‡è¦ä¿¡æ¯")
    else:
        st.info("ğŸŸ¡ ç­‰å¾…å¯¹è¯å¼€å§‹")
