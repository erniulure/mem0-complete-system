"""
ç°ä»£åŒ–èŠå¤©ç•Œé¢ - ä½¿ç”¨streamlit-chat-promptç»„ä»¶
"""

import streamlit as st
import base64
import io
import requests
import json
import os
from datetime import datetime
from streamlit_chat_prompt import prompt

class SimpleImageProcessor:
    """ç®€å•çš„å›¾ç‰‡å¤„ç†å™¨å¤‡ç”¨ç±»"""

    @staticmethod
    def process_image(image_data):
        """ç®€å•çš„å›¾ç‰‡å¤„ç†"""
        try:
            from PIL import Image
            import base64
            import io

            if isinstance(image_data, str):
                # base64å­—ç¬¦ä¸²
                if image_data.startswith('data:image'):
                    image_data = image_data.split(',')[1]

                img_bytes = base64.b64decode(image_data)
                img = Image.open(io.BytesIO(img_bytes))
            else:
                # æ–‡ä»¶å¯¹è±¡
                img = Image.open(image_data)

            # è·å–åŸºæœ¬ä¿¡æ¯
            width, height = img.size
            format_type = img.format or 'PNG'

            # è½¬æ¢ä¸ºbase64
            buffer = io.BytesIO()
            img.save(buffer, format=format_type)
            size_bytes = len(buffer.getvalue())
            buffer.seek(0)
            img_base64 = base64.b64encode(buffer.getvalue()).decode()

            return {
                "success": True,
                "base64": img_base64,
                "width": width,
                "height": height,
                "format": format_type,
                "size_bytes": size_bytes,
                "size_mb": round(size_bytes / 1024 / 1024, 2)
            }
        except Exception as e:
            return {
                "success": False,
                "error": str(e)
            }

def ensure_multimodal_processor():
    """ç¡®ä¿multimodal_processorå·²åˆå§‹åŒ–"""
    if 'multimodal_processor' not in st.session_state:
        try:
            from multimodal_model_selector import MultimodalProcessor
            st.session_state.multimodal_processor = MultimodalProcessor()
        except Exception as e:
            st.error(f"âŒ åˆå§‹åŒ–å¤šæ¨¡æ€å¤„ç†å™¨å¤±è´¥: {str(e)}")
            # åˆ›å»ºä¸€ä¸ªç®€å•çš„å¤‡ç”¨å¤„ç†å™¨
            st.session_state.multimodal_processor = SimpleImageProcessor()

def handle_modern_chat_message(user_text: str, image_info: dict = None):
    """å¤„ç†ç°ä»£åŒ–èŠå¤©æ¶ˆæ¯ - é›†æˆæ™ºèƒ½è®°å¿†åŠŸèƒ½"""
    try:
        # åˆå§‹åŒ–æ™ºèƒ½è®°å¿†ç®¡ç†å™¨
        if 'memory_manager' not in st.session_state:
            from intelligent_memory_manager import IntelligentMemoryManager
            from api_patches import MemoryAPIPatched

            user_id = getattr(st.session_state, 'user_settings', {}).get('user_id', 'default_user')
            mem0_api_url = MemoryAPIPatched.get_api_url()

            st.session_state.memory_manager = IntelligentMemoryManager(
                mem0_api_url=mem0_api_url,
                user_id=user_id
            )

        memory_manager = st.session_state.memory_manager

        # æ™ºèƒ½æ¨¡å‹é€‰æ‹©
        has_image = image_info is not None and image_info.get("success", False)
        content_for_analysis = user_text or "å›¾ç‰‡åˆ†æè¯·æ±‚"

        # ç¡®ä¿model_selectorå·²åˆå§‹åŒ–
        if 'model_selector' not in st.session_state:
            from dynamic_model_selector import DynamicModelSelector
            api_key = st.session_state.get('api_settings', {}).get('api_key', 'q1q2q3q4')
            st.session_state.model_selector = DynamicModelSelector(
                api_base_url='http://gemini-balance:8000',
                api_key=api_key
            )

        # é€‰æ‹©åˆé€‚çš„æ¨¡å‹
        model_info = st.session_state.model_selector.select_optimal_model(
            user_query=content_for_analysis,
            has_image=has_image
        )

        # ğŸ§  ç®€åŒ–è®°å¿†æ£€ç´¢ï¼šé»˜è®¤æ€»æ˜¯æ£€ç´¢è®°å¿†ï¼ˆé™¤éæ˜¯æ˜æ˜¾çš„åƒåœ¾å†…å®¹ï¼‰
        should_skip_memory = (
            len(user_text.strip()) < 2 or  # å¤ªçŸ­
            user_text.strip() in ['hi', 'hello', 'ä½ å¥½', 'ok', 'yes', 'no'] or  # ç®€å•é—®å€™
            user_text.strip().startswith('/')  # å‘½ä»¤
        )

        if not should_skip_memory:
            with st.spinner("ğŸ§  æ­£åœ¨å›å¿†ç›¸å…³ä¿¡æ¯..."):
                # ğŸ” æœç´¢ç›¸å…³è®°å¿†ï¼ˆä½¿ç”¨åŒæ­¥ç‰ˆæœ¬ï¼‰
                relevant_memories = memory_manager.search_relevant_memories_sync(user_text, limit=5)

                # ğŸ“ æ„å»ºå¢å¼ºçš„ä¸Šä¸‹æ–‡
                enhanced_user_input = memory_manager.build_context_with_memories(
                    user_text, relevant_memories, {'needs_memory': True, 'confidence': 1.0}
                )
        else:
            enhanced_user_input = user_text
            relevant_memories = []

        # ç®€åŒ–çš„è®°å¿†åˆ†æç»“æœ
        memory_analysis = {
            'needs_memory': not should_skip_memory,
            'confidence': 1.0 if not should_skip_memory else 0.0,
            'trigger_type': 'default' if not should_skip_memory else 'skip',
            'keywords': []
        }

        # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ°èŠå¤©å†å²
        user_message = {
            "role": "user",
            "content": user_text,
            "timestamp": st.session_state.get('current_time', ''),
            "model_info": model_info,
            "memory_analysis": memory_analysis,
            "used_memories": len(relevant_memories)
        }

        if image_info:
            user_message["image_info"] = image_info

        st.session_state.chat_history.append(user_message)
        
        # ğŸ¤– æ™ºèƒ½å¯¹è¯ç³»ç»Ÿ - é›†æˆè®°å¿†åŠŸèƒ½

        # è·å–ç”¨æˆ·ID
        user_id = getattr(st.session_state, 'user_settings', {}).get('user_id', 'default_user')

        # è°ƒç”¨gemini-balanceè·å–AIå›å¤
        gemini_balance_url = os.getenv('GEMINI_BALANCE_URL', 'http://gemini-balance:8000/v1')
        auth_token = st.session_state.get('api_settings', {}).get('api_key') or os.getenv('INTEGRATED_GEMINI_BALANCE_TOKEN', os.getenv('GEMINI_BALANCE_TOKEN', 'q1q2q3q4'))

        # æ„å»ºæ™ºèƒ½å¯¹è¯æ¶ˆæ¯
        messages = [
            {
                "role": "system",
                "content": """ä½ æ˜¯ä¸€ä¸ªå…·æœ‰è®°å¿†èƒ½åŠ›çš„æ™ºèƒ½åŠ©æ‰‹ã€‚ä½ èƒ½å¤Ÿï¼š
1. è®°ä½ç”¨æˆ·çš„ä¸ªäººä¿¡æ¯ã€åå¥½å’Œå†å²å¯¹è¯
2. åŸºäºå†å²è®°å¿†æä¾›ä¸ªæ€§åŒ–çš„å›å¤
3. è‡ªç„¶åœ°å¼•ç”¨ç›¸å…³çš„å†å²ä¿¡æ¯
4. åœ¨ä¿¡æ¯ä¸ç¡®å®šæ—¶ä¸»åŠ¨è¯¢é—®ç”¨æˆ·ç¡®è®¤

è¯·ç”¨ä¸­æ–‡å›å¤ï¼Œä¿æŒå¯¹è¯çš„è‡ªç„¶æ€§å’Œè¿è´¯æ€§ã€‚"""
            }
        ]

        # æ·»åŠ èŠå¤©å†å²ï¼ˆæœ€è¿‘5æ¡ï¼Œä¸åŒ…æ‹¬å½“å‰æ¶ˆæ¯ï¼‰
        recent_history = st.session_state.chat_history[-10:] if len(st.session_state.chat_history) > 1 else []
        for msg in recent_history:
            if msg['role'] in ['user', 'assistant']:
                messages.append({
                    "role": msg['role'],
                    "content": msg['content']
                })

        # æ·»åŠ å¢å¼ºçš„ç”¨æˆ·æ¶ˆæ¯ï¼ˆåŒ…å«è®°å¿†ä¸Šä¸‹æ–‡å’Œå›¾ç‰‡ï¼‰
        user_message_content = enhanced_user_input  # ä½¿ç”¨å¢å¼ºçš„è¾“å…¥è€Œä¸æ˜¯åŸå§‹è¾“å…¥

        # å¦‚æœæœ‰å›¾ç‰‡ï¼Œæ„å»ºå¤šæ¨¡æ€æ¶ˆæ¯æ ¼å¼
        if image_info and image_info.get("success"):
            # ä½¿ç”¨OpenAIå…¼å®¹çš„å¤šæ¨¡æ€æ¶ˆæ¯æ ¼å¼
            messages.append({
                "role": "user",
                "content": [
                    {
                        "type": "text",
                        "text": user_message_content
                    },
                    {
                        "type": "image_url",
                        "image_url": {
                            "url": f"data:image/{image_info.get('format', 'png').lower()};base64,{image_info['base64']}"
                        }
                    }
                ]
            })
        else:
            # çº¯æ–‡æœ¬æ¶ˆæ¯
            messages.append({
                "role": "user",
                "content": user_message_content
            })

        # è°ƒç”¨gemini-balance API
        payload = {
            "model": model_info.get('selected_model', 'gemini-1.5-flash'),
            "messages": messages,
            "temperature": 0.7,
            "max_tokens": 2000
        }

        headers = {
            "Authorization": f"Bearer {auth_token}",
            "Content-Type": "application/json"
        }

        response = requests.post(
            f"{gemini_balance_url}/chat/completions",
            json=payload,
            headers=headers,
            timeout=30
        )

        if response.status_code != 200:
            raise Exception(f"Gemini Balance APIè°ƒç”¨å¤±è´¥: {response.status_code} - {response.text}")

        result = response.json()
        ai_response = result.get("choices", [{}])[0].get("message", {}).get("content", "æŠ±æ­‰ï¼Œæˆ‘æ— æ³•å¤„ç†æ‚¨çš„è¯·æ±‚ã€‚")

        # ğŸ§  æ™ºèƒ½è®°å¿†å­˜å‚¨ï¼šAIè‡ªåŠ¨åˆ¤æ–­æ˜¯å¦å­˜å‚¨å¯¹è¯
        memory_storage_result = None
        try:
            with st.spinner("ğŸ§  AIæ­£åœ¨åˆ†ææ˜¯å¦éœ€è¦è®°ä½è¿™æ¬¡å¯¹è¯..."):
                memory_storage_result = memory_manager.intelligent_store_memory_sync(
                    user_text, ai_response
                )

                # æ˜¾ç¤ºè®°å¿†å­˜å‚¨çŠ¶æ€ï¼ˆå¯é€‰ï¼‰
                if memory_storage_result['stored']:
                    st.success(f"âœ… {memory_storage_result['reason']}")
                elif memory_storage_result['confidence'] > 0.2:
                    st.info(f"â„¹ï¸ {memory_storage_result['reason']}")

        except Exception as memory_error:
            # è®°å¿†å­˜å‚¨å¤±è´¥ä¸å½±å“å¯¹è¯åŠŸèƒ½
            print(f"æ™ºèƒ½è®°å¿†å­˜å‚¨å¤±è´¥: {memory_error}")
            memory_storage_result = {
                'stored': False,
                'reason': f"å­˜å‚¨å¤±è´¥: {str(memory_error)}",
                'value_level': 'unknown',
                'confidence': 0.0
            }

        # æ·»åŠ AIå›å¤åˆ°èŠå¤©å†å²ï¼ˆåŒ…å«è®°å¿†ä¿¡æ¯ï¼‰
        assistant_message = {
            "role": "assistant",
            "content": ai_response,
            "timestamp": st.session_state.get('current_time', ''),
            "model": model_info.get('selected_model', 'unknown'),
            "memory_storage": memory_storage_result,
            "used_memories": len(relevant_memories) if relevant_memories else 0
        }
        st.session_state.chat_history.append(assistant_message)

        # æ›´æ–°å­¦ä¹ çŠ¶æ€
        st.session_state.learning_state = "active"

        # å¯¹è¯æˆåŠŸåè‡ªåŠ¨æ›´æ–°è¿æ¥çŠ¶æ€
        st.session_state.api_connected = True
        if 'api_settings' in st.session_state:
            st.session_state.api_settings['connected'] = True

        # æ˜¾ç¤ºè®°å¿†é€æ˜åº¦ä¿¡æ¯ï¼ˆå¯é€‰ï¼‰
        if relevant_memories:
            with st.expander(f"ğŸ§  æœ¬æ¬¡å¯¹è¯ä½¿ç”¨äº† {len(relevant_memories)} æ¡å†å²è®°å¿†", expanded=False):
                for i, memory in enumerate(relevant_memories[:3], 1):
                    st.write(f"**è®°å¿† {i}** (ç›¸å…³åº¦: {memory.get('score', 0.0):.2f})")
                    st.write(memory.get('memory', '')[:200] + "..." if len(memory.get('memory', '')) > 200 else memory.get('memory', ''))
                    st.write("---")

        st.rerun()

    except requests.exceptions.Timeout:
        # å¯¹è¯å¤±è´¥æ—¶æ›´æ–°è¿æ¥çŠ¶æ€
        st.session_state.api_connected = False
        if 'api_settings' in st.session_state:
            st.session_state.api_settings['connected'] = False
        st.error("â° è¯·æ±‚è¶…æ—¶ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–ç¨åé‡è¯•")
        st.info("ğŸ’¡ å»ºè®®ï¼šæ£€æŸ¥AIæœåŠ¡æ˜¯å¦æ­£å¸¸è¿è¡Œ")
    except requests.exceptions.ConnectionError:
        # å¯¹è¯å¤±è´¥æ—¶æ›´æ–°è¿æ¥çŠ¶æ€
        st.session_state.api_connected = False
        if 'api_settings' in st.session_state:
            st.session_state.api_settings['connected'] = False
        st.error("ğŸ”Œ æ— æ³•è¿æ¥åˆ°AIæœåŠ¡ï¼Œè¯·æ£€æŸ¥æœåŠ¡çŠ¶æ€")
        st.info("ğŸ’¡ å»ºè®®ï¼šç¡®è®¤gemini-balanceæœåŠ¡æ­£åœ¨è¿è¡Œ")
    except Exception as e:
        # å¯¹è¯å¤±è´¥æ—¶æ›´æ–°è¿æ¥çŠ¶æ€
        st.session_state.api_connected = False
        if 'api_settings' in st.session_state:
            st.session_state.api_settings['connected'] = False
        st.error(f"âŒ å¤„ç†æ¶ˆæ¯æ—¶å‡ºé”™: {str(e)}")
        st.info("ğŸ’¡ å»ºè®®ï¼š\n1. æ£€æŸ¥ç½‘ç»œè¿æ¥\n2. ç¡®è®¤AIæœåŠ¡æ­£å¸¸è¿è¡Œ\n3. å¦‚é—®é¢˜æŒç»­ï¼Œè¯·è”ç³»ç®¡ç†å‘˜")

def modern_smart_chat_interface():
    """ç°ä»£åŒ–æ™ºèƒ½å¯¹è¯ç•Œé¢"""
    st.header("ğŸ§  æ™ºèƒ½å¯¹è¯ - AIè®°å¿†å­¦ä¹ ä¸­å¿ƒ")
    st.markdown("ä¸AIåŠ©æ‰‹å¯¹è¯ï¼Œè§‚å¯ŸAIå¦‚ä½•è‡ªåŠ¨å­¦ä¹ å’Œè®°å¿†æ‚¨çš„åå¥½")

    # åˆ›å»ºå·¦å³åˆ†åˆ—å¸ƒå±€
    chat_col, memory_col = st.columns([2, 1])

    with chat_col:
        st.subheader("ğŸ’¬ å¯¹è¯åŒºåŸŸ")

        # æ˜¾ç¤ºèŠå¤©å†å² - ä½¿ç”¨ç°ä»£åŒ–çš„èŠå¤©æ¶ˆæ¯ç»„ä»¶
        for message in st.session_state.chat_history:
            with st.chat_message(message['role']):
                if message['role'] == 'user':
                    st.write(message['content'])
                    # æ˜¾ç¤ºå›¾ç‰‡ï¼ˆå¦‚æœæœ‰ï¼‰
                    if 'image_info' in message and message['image_info']:
                        st.caption("ğŸ“· åŒ…å«å›¾ç‰‡")
                    # æ˜¾ç¤ºæ¨¡å‹ä¿¡æ¯ï¼ˆå¦‚æœæœ‰ï¼‰
                    if 'model_info' in message:
                        model_info = message['model_info']
                        st.caption(f"ğŸ¤– ä½¿ç”¨æ¨¡å‹: {model_info.get('selected_model', 'unknown')}")
                else:
                    st.write(message['content'])
                    if 'model' in message:
                        st.caption(f"ğŸ¤– æ¨¡å‹: {message['model']}")

        # ç°ä»£åŒ–èŠå¤©è¾“å…¥ç»„ä»¶ - æ”¯æŒEnterå‘é€ï¼ŒShift+Enteræ¢è¡Œï¼Œå‰ªè´´æ¿ç²˜è´´
        prompt_result = prompt(
            name="chat_input",
            key="modern_chat_prompt",
            placeholder="è¾“å…¥æ‚¨çš„æ¶ˆæ¯... (Enterå‘é€ï¼ŒShift+Enteræ¢è¡Œï¼Œæ”¯æŒç²˜è´´å›¾ç‰‡)",
            main_bottom=False,  # ä¸å›ºå®šåœ¨é¡µé¢åº•éƒ¨ï¼Œè€Œæ˜¯åœ¨å¯¹è¯åŒºåŸŸå†…
        )

        # å¤„ç†ç°ä»£åŒ–èŠå¤©è¾“å…¥
        if prompt_result:
            # è·å–ç”¨æˆ·è¾“å…¥çš„æ–‡æœ¬
            user_text = prompt_result.text if prompt_result.text else ""
            user_text = user_text.strip()
            
            # è·å–ç”¨æˆ·ä¸Šä¼ /ç²˜è´´çš„å›¾ç‰‡
            user_images = prompt_result.images if prompt_result.images else []
            
            if user_text or user_images:
                # å¤„ç†å›¾ç‰‡æ•°æ®
                image_info = None
                if user_images:
                    try:
                        # ç¡®ä¿å¤šæ¨¡æ€å¤„ç†å™¨å·²åˆå§‹åŒ–
                        ensure_multimodal_processor()

                        # ä½¿ç”¨ç¬¬ä¸€å¼ å›¾ç‰‡
                        first_image = user_images[0]

                        # first_image æ˜¯ FileData å¯¹è±¡ï¼Œç›´æ¥ä½¿ç”¨å…¶ data å±æ€§ï¼ˆbase64æ•°æ®ï¼‰
                        img_base64 = first_image.data

                        # å¤„ç†å›¾ç‰‡
                        image_info = st.session_state.multimodal_processor.process_image(img_base64)
                        if not image_info["success"]:
                            st.error(f"âŒ å›¾ç‰‡å¤„ç†å¤±è´¥: {image_info['error']}")
                            image_info = None
                    except Exception as e:
                        st.error(f"âŒ å›¾ç‰‡å¤„ç†å¼‚å¸¸: {str(e)}")
                        image_info = None
                
                # å‘é€æ¶ˆæ¯
                if user_text:
                    handle_modern_chat_message(user_text, image_info)

        # æ¸…ç©ºå¯¹è¯æŒ‰é’®
        if st.button("ğŸ§¹ æ¸…ç©ºå¯¹è¯", type="secondary"):
            st.session_state.chat_history = []
            st.rerun()

    with memory_col:
        st.subheader("ğŸ§  AIè®°å¿†å­¦ä¹ ")
        display_real_time_memory_learning()

def display_real_time_memory_learning():
    """æ˜¾ç¤ºAIå®æ—¶è®°å¿†å­¦ä¹ è¿‡ç¨‹"""
    
    # è·å–æœ€è¿‘å­¦ä¹ çš„è®°å¿†
    if 'recent_memories' not in st.session_state:
        st.session_state.recent_memories = []

    # æ˜¾ç¤ºæœ€è¿‘å­¦ä¹ çš„è®°å¿†
    if st.session_state.recent_memories:
        st.markdown("### ğŸ†• AIåˆšå­¦åˆ°çš„è®°å¿†")
        for memory in st.session_state.recent_memories[-3:]:  # æ˜¾ç¤ºæœ€è¿‘3æ¡
            with st.expander(f"ğŸ’¡ {memory.get('summary', 'æ–°è®°å¿†')}", expanded=True):
                st.write(f"**å†…å®¹**: {memory.get('content', '')}")
                st.write(f"**æ—¶é—´**: {memory.get('timestamp', '')}")
                if memory.get('confidence'):
                    st.progress(memory['confidence'], text=f"ç½®ä¿¡åº¦: {memory['confidence']:.0%}")
    else:
        st.info("ğŸ’­ AIæ­£åœ¨ç­‰å¾…å­¦ä¹ æ–°çš„è®°å¿†...")

    # æ˜¾ç¤ºè®°å¿†ç»Ÿè®¡
    st.markdown("### ğŸ“Š è®°å¿†ç»Ÿè®¡")

    # åˆå§‹åŒ–å˜é‡
    all_memories = []
    user_id = getattr(st.session_state, 'user_settings', {}).get('user_id', 'default_user')
    import os
    api_base_url = getattr(st.session_state, 'api_base_url', os.getenv('MEM0_API_URL', 'http://localhost:8888'))

    try:

        # è·å–è®°å¿†åˆ—è¡¨æ¥è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        import requests
        from datetime import datetime, date

        memories_response = requests.get(
            f"{api_base_url}/memories",
            params={"user_id": user_id},
            timeout=10
        )

        if memories_response.status_code == 200:
            memories_data = memories_response.json()

            # å¤„ç†APIè¿”å›çš„æ•°æ®ç»“æ„
            if isinstance(memories_data, dict) and 'results' in memories_data:
                if isinstance(memories_data['results'], dict) and 'results' in memories_data['results']:
                    all_memories = memories_data['results']['results']
                else:
                    all_memories = memories_data['results']
            elif isinstance(memories_data, list):
                all_memories = memories_data
            else:
                all_memories = []

            # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
            total_memories = len(all_memories)
            today = date.today().isoformat()
            today_added = sum(1 for memory in all_memories
                            if memory.get('created_at', '').startswith(today))

            col1, col2 = st.columns(2)
            with col1:
                st.metric("æ€»è®°å¿†æ•°é‡", total_memories)
            with col2:
                st.metric("ä»Šæ—¥æ–°å¢", today_added)

        else:
            st.error("âŒ æ— æ³•è·å–è®°å¿†ç»Ÿè®¡")
            
    except Exception as e:
        st.error(f"âŒ è·å–ç»Ÿè®¡å¤±è´¥: {str(e)}")

    # æ˜¾ç¤ºè®°å¿†æ ‡ç­¾äº‘
    st.markdown("### ğŸ·ï¸ è®°å¿†æ ‡ç­¾")
    
    try:
        # ä»å·²è·å–çš„è®°å¿†ä¸­æå–æ ‡ç­¾
        if 'all_memories' in locals() and all_memories:
            # æå–è®°å¿†ä¸­çš„å…³é”®è¯ä½œä¸ºæ ‡ç­¾
            tags = set()
            for memory in all_memories[:10]:  # åªå¤„ç†æœ€è¿‘10æ¡
                content = memory.get('memory', memory.get('content', ''))
                # ç®€å•çš„å…³é”®è¯æå–
                words = content.split()
                for word in words:
                    if len(word) > 2 and word.isalpha():
                        tags.add(word)

            if tags:
                tag_list = list(tags)[:8]  # æœ€å¤šæ˜¾ç¤º8ä¸ªæ ‡ç­¾
                cols = st.columns(2)
                for i, tag in enumerate(tag_list):
                    with cols[i % 2]:
                        st.button(f"#{tag}", disabled=True, key=f"tag_{i}")
            else:
                st.info("ğŸ·ï¸ æš‚æ— æ ‡ç­¾")
        else:
            st.info("ğŸ·ï¸ æš‚æ— æ ‡ç­¾")

    except Exception as e:
        st.info("ğŸ·ï¸ æ ‡ç­¾åŠ è½½ä¸­...")

    # å­¦ä¹ çŠ¶æ€æŒ‡ç¤ºå™¨
    st.markdown("### âš¡ å­¦ä¹ çŠ¶æ€")
    
    if len(st.session_state.chat_history) > 0:
        st.success("ğŸŸ¢ AIæ­£åœ¨ç§¯æå­¦ä¹ ä¸­")
        st.write("AIä¼šè‡ªåŠ¨ä»æ¯æ¬¡å¯¹è¯ä¸­æå–é‡è¦ä¿¡æ¯")
    else:
        st.info("ğŸŸ¡ ç­‰å¾…å¯¹è¯å¼€å§‹")
